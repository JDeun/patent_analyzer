import streamlit as st
import os
import fitz  # PyMuPDF
from PIL import Image
import io
import base64 # PDF ë·°ì–´ì—ì„œ ì§ì ‘ ì‚¬ìš©ë˜ì§„ ì•Šì§€ë§Œ, ë‹¤ë¥¸ ê¸°ëŠ¥ì— í•„ìš”í•  ìˆ˜ ìˆìŒ
import json
import traceback
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage

# --- ì™¸ë¶€ íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë° ìŠ¤í‚¤ë§ˆ ì„¤ëª… ì„í¬íŠ¸ ---
try:
    from prompts import PATENT_DATA_SCHEMA_FOR_LLM_PROMPT_FULL
    from schema_descriptions import SCHEMA_FIELD_DESCRIPTIONS
except ImportError:
    st.error("ì˜¤ë¥˜: `prompts.py` ë˜ëŠ” `schema_descriptions.py` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ë“¤ì´ main ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    # ëŒ€ì²´ ê°’ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ë‹¨ ë˜ëŠ” ê¸°ë³¸ê°’ ì„¤ì •
    PATENT_DATA_SCHEMA_FOR_LLM_PROMPT_FULL = "{}" # ë¹ˆ JSONì´ë¼ë„ LLM í˜¸ì¶œì€ ì‹œë„ë  ìˆ˜ ìˆìŒ
    SCHEMA_FIELD_DESCRIPTIONS = {}
    # st.stop() # ë˜ëŠ” ì•± ì‹¤í–‰ì„ ì¤‘ë‹¨

# --- ì „ì—­ ì„¤ì • ë³€ìˆ˜ ---
GEMINI_MODEL_NAME = "gemini-2.5-flash-preview-05-20"
TEMPERATURE = 0.0
API_REQUEST_TIMEOUT_STRUCTURED_DATA = 1200 # ì´ˆ ë‹¨ìœ„ (20ë¶„)

DEFAULT_DPI = 300 # PDF í˜ì´ì§€ ì´ë¯¸ì§€ ë³€í™˜ ì‹œ DPI (ë””ë²„ê¹…ìš©)

# ë””ë²„ê¹… ê´€ë ¨ ì„¤ì •
SAVE_DEBUG_PDF_IMAGES = True
DEBUG_OUTPUT_BASE_DIR = "debug_output"
# ---------------------

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Google API í‚¤ í™•ì¸ ë° LLM ì´ˆê¸°í™”
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
llm = None
if not GOOGLE_API_KEY:
    # Streamlit ì•±ì—ì„œëŠ” st.errorë¥¼ ë¨¼ì € ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ë‚˜ì¤‘ì— ì•± ì‹¤í–‰ ì‹œì ì— í™•ì¸
    print("CRITICAL: GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•± ì‹¤í–‰ ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.")
else:
    try:
        llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL_NAME, google_api_key=GOOGLE_API_KEY, temperature=TEMPERATURE)
        print(f"Gemini ëª¨ë¸ '{GEMINI_MODEL_NAME}' ì´ˆê¸°í™” ì„±ê³µ.")
    except Exception as e_model_init:
        print(f"Gemini ëª¨ë¸ '{GEMINI_MODEL_NAME}' ì´ˆê¸°í™” ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e_model_init}")
        llm = None

def extract_text_from_pdf_page_st(page: fitz.Page) -> str:
    try:
        text = page.get_text("text", sort=True)
        return text
    except Exception as e:
        st.error(f"í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return ""

def convert_pdf_to_text_st(uploaded_file_content: bytes, pdf_filename_for_debug: str) -> tuple[list[str], str]:
    full_text_for_extraction = ""
    page_texts = []

    debug_image_dir = None
    if SAVE_DEBUG_PDF_IMAGES:
        pdf_base_filename = os.path.splitext(pdf_filename_for_debug)[0]
        debug_image_dir = os.path.join(DEBUG_OUTPUT_BASE_DIR, pdf_base_filename, "pdf_to_images_debug")
        os.makedirs(debug_image_dir, exist_ok=True)

    try:
        doc = fitz.open(stream=uploaded_file_content, filetype="pdf")
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            actual_page_num = page_num + 1
            text = extract_text_from_pdf_page_st(page)
            page_texts.append(text)
            full_text_for_extraction += f"\n\n<<<<< PAGE {actual_page_num} / {len(doc)} >>>>>\n\n" + text

            if SAVE_DEBUG_PDF_IMAGES and debug_image_dir:
                zoom = DEFAULT_DPI / 72
                matrix = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=matrix, alpha=False)
                img_bytes = pix.tobytes("png")
                pil_image = Image.open(io.BytesIO(img_bytes))
                img_save_path = os.path.join(debug_image_dir, f"{os.path.splitext(pdf_filename_for_debug)[0]}_page_{actual_page_num}_dpi{DEFAULT_DPI}.png")
                try:
                    pil_image.save(img_save_path)
                except Exception as e_save_img_debug:
                    st.warning(f"ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨ (í˜ì´ì§€ {actual_page_num}): {e_save_img_debug}")
        doc.close()

        if page_texts:
            pdf_base_filename = os.path.splitext(pdf_filename_for_debug)[0]
            debug_text_dir = os.path.join(DEBUG_OUTPUT_BASE_DIR, pdf_base_filename)
            os.makedirs(debug_text_dir, exist_ok=True)
            text_output_file = os.path.join(debug_text_dir, f"{pdf_base_filename}_extracted_full_text.txt")
            try:
                with open(text_output_file, "w", encoding="utf-8") as f:
                    f.write(full_text_for_extraction)
                st.sidebar.info(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ '{text_output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e_text_save:
                st.sidebar.warning(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e_text_save}")
        return page_texts, full_text_for_extraction
    except Exception as e:
        st.error(f"PyMuPDFë¡œ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return [], ""

def extract_structured_data_from_full_text_st(
    full_patent_text: str,
    model: ChatGoogleGenerativeAI,
    pdf_filename: str
) -> dict:
    if not full_patent_text.strip():
        st.warning("êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œì„ ìœ„í•œ ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {"error": "Input text for structured data extraction is empty.", "source_file_name": pdf_filename, "language_of_document": "Unknown"}

    # PATENT_DATA_SCHEMA_FOR_LLM_PROMPT_FULLì€ prompts.pyì—ì„œ ì„í¬íŠ¸ë©ë‹ˆë‹¤.
    final_prompt = PATENT_DATA_SCHEMA_FOR_LLM_PROMPT_FULL + \
                   f"\n\nIMPORTANT:\n" + \
                   f"- The 'source_file_name' field in the JSON output MUST be exactly: \"{pdf_filename}\"\n" + \
                   f"- Identify the primary language of the patent text and set the 'language_of_document' field accordingly (e.g., 'English', 'Korean').\n" + \
                   f"- Ensure the 'document_summary_for_user' field contains a concise 3-5 sentence general summary.\n\n" + \
                   "Here is the full patent text to analyze:\n\n--- BEGIN PATENT TEXT ---\n" + \
                   full_patent_text + \
                   "\n--- END PATENT TEXT ---\n\n" + \
                   "Extract the information based on the schema provided above and provide ONLY the JSON object as your response."
    
    messages = [HumanMessage(content=final_prompt)]

    try:
        st.info(f"LLM ({GEMINI_MODEL_NAME}) í˜¸ì¶œí•˜ì—¬ íŠ¹í—ˆ í•µì‹¬ ì •ë³´ ì¶”ì¶œ ì¤‘... (íŒŒì¼ëª…: {pdf_filename}). ì´ ì‘ì—…ì€ ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        response = model.invoke(messages, config={"request_timeout": API_REQUEST_TIMEOUT_STRUCTURED_DATA})

        if response and hasattr(response, 'content') and isinstance(response.content, str) and response.content.strip():
            content_str = response.content.strip()
            if content_str.startswith("```json"):
                content_str = content_str[len("```json"):].strip()
            if content_str.endswith("```"):
                content_str = content_str[:-len("```")].strip()

            try:
                structured_data = json.loads(content_str)
                if "source_file_name" not in structured_data: # LLMì´ ë¹¼ë¨¹ì—ˆì„ ê²½ìš° ëŒ€ë¹„
                    structured_data["source_file_name"] = pdf_filename
                if "language_of_document" not in structured_data:
                    if any(char.isalpha() and ord(char) > 127 for char in full_patent_text[:2000]):
                        structured_data["language_of_document"] = "Non-English (Auto-Detected)"
                    else:
                        structured_data["language_of_document"] = "English (Auto-Detected)"
                if "document_summary_for_user" not in structured_data:
                     structured_data["document_summary_for_user"] = "ìš”ì•½ ì •ë³´ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                return structured_data
            except json.JSONDecodeError as json_e:
                st.error(f"LLM ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {json_e}")
                st.text_area("LLM ì›ë³¸ ì‘ë‹µ (íŒŒì‹± ì‹¤íŒ¨)", content_str[:3000], height=300)
                return {"error": "Failed to parse LLM response as JSON", "raw_response": content_str, "source_file_name": pdf_filename, "language_of_document": "Unknown"}
            except TypeError as type_e:
                st.error(f"LLM ì‘ë‹µ JSON íŒŒì‹± ì¤‘ TypeError: {type_e}")
                st.text_area("LLM ì›ë³¸ ì‘ë‹µ (TypeError)", str(content_str)[:3000], height=300)
                return {"error": "LLM response was not suitable for JSON parsing (e.g. None type)", "raw_response": str(content_str), "source_file_name": pdf_filename, "language_of_document": "Unknown"}
        else:
            st.error("LLMìœ¼ë¡œë¶€í„° ìœ íš¨í•œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (êµ¬ì¡°í™” ë°ì´í„° ì¶”ì¶œ).")
            err_payload = {"error": "Invalid or empty response from LLM for structured data extraction.", "source_file_name": pdf_filename, "language_of_document": "Unknown"}
            if response and hasattr(response, 'candidates') and response.candidates:
                for i, cand in enumerate(response.candidates):
                    finish_reason = getattr(cand, 'finish_reason', 'N/A')
                    safety_ratings = getattr(cand, 'safety_ratings', [])
                    err_payload[f'candidate_{i}_finish_reason'] = str(finish_reason)
                    err_payload[f'candidate_{i}_safety_ratings'] = str(safety_ratings)
            elif response and hasattr(response, 'parts') and not response.parts:
                 err_payload['details'] = "Response object had no 'parts'."
            st.json(err_payload)
            return err_payload

    except Exception as e:
        st.error(f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ (êµ¬ì¡°í™” ë°ì´í„° ì¶”ì¶œ): {e}")
        st.text_area("LLM í˜¸ì¶œ ì˜¤ë¥˜ ìƒì„¸", traceback.format_exc(), height=300)
        return {"error": f"API call failed: {str(e)}", "traceback": traceback.format_exc(), "source_file_name": pdf_filename, "language_of_document": "Unknown"}

@st.cache_data
def render_pdf_page_as_image(pdf_bytes, page_num, dpi=150):
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        if 0 <= page_num < len(doc):
            page = doc.load_page(page_num)
            zoom = dpi / 72
            matrix = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=matrix, alpha=False)
            img = Image.open(io.BytesIO(pix.tobytes("png")))
            doc.close()
            return img
        doc.close()
        return None
    except Exception:
        return None

def get_value_by_path(data_dict, path_string):
    keys = path_string.split('.')
    val = data_dict
    try:
        for key in keys:
            if isinstance(val, list) and key.isdigit():
                idx = int(key)
                if 0 <= idx < len(val):
                    val = val[idx]
                else:
                    return None # Index out of bounds
            elif isinstance(val, dict):
                val = val[key]
            else: # Path tries to go deeper, but current val is not a dict or list
                return None
        return val
    except (KeyError, TypeError, IndexError, AttributeError):
        return None

# --- Streamlit UI êµ¬ì„± ---
st.set_page_config(page_title="íŠ¹í—ˆ ë¬¸ì„œ ë¶„ì„ í”„ë¡œí† íƒ€ì…", layout="wide")
st.title("ğŸ“œ íŠ¹í—ˆ ë¬¸ì„œ ë¶„ì„ í”„ë¡œí† íƒ€ì… v3 (ìŠ¤í‚¤ë§ˆ ì„¤ëª… ë¶„ë¦¬)")
st.markdown("PDF íŠ¹í—ˆ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ì£¼ìš” ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ JSON ë°ì´í„°ë¡œ ì œê³µí•˜ê³ , ê° í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ì„ í•¨ê»˜ ë³´ì—¬ì¤ë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'structured_data' not in st.session_state:
    st.session_state.structured_data = None
if 'pdf_page_texts' not in st.session_state:
    st.session_state.pdf_page_texts = []
if 'current_page_for_pdf_view' not in st.session_state:
    st.session_state.current_page_for_pdf_view = 0
if 'original_filename' not in st.session_state:
    st.session_state.original_filename = ""

uploaded_file = st.file_uploader("íŠ¹í—ˆ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (.pdf)", type="pdf", key="pdf_uploader")

if uploaded_file is not None:
    if st.button("íŠ¹í—ˆ ë¶„ì„ ì‹œì‘", key="analyze_button"):
        st.session_state.analysis_complete = False
        st.session_state.structured_data = None
        st.session_state.pdf_page_texts = []
        st.session_state.current_page_for_pdf_view = 0
        st.session_state.original_filename = uploaded_file.name

        with st.spinner(f"'{uploaded_file.name}' ë¶„ì„ ì¤‘... PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ LLM í˜¸ì¶œ ì¤‘ì…ë‹ˆë‹¤. ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤..."):
            if llm is None:
                st.error("LLM ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GOOGLE_API_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                st.stop()

            try:
                pdf_bytes = uploaded_file.getvalue()
                st.session_state.pdf_bytes_for_viewer = pdf_bytes

                page_texts, full_text_from_pdf = convert_pdf_to_text_st(pdf_bytes, uploaded_file.name)
                st.session_state.pdf_page_texts = page_texts

                if not full_text_from_pdf.strip():
                    st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.stop()

                extracted_data = extract_structured_data_from_full_text_st(
                    full_text_from_pdf,
                    llm,
                    uploaded_file.name
                )
                st.session_state.structured_data = extracted_data
                st.session_state.analysis_complete = True
                st.success(f"'{uploaded_file.name}' ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.exception(e)
                st.session_state.analysis_complete = False

if st.session_state.analysis_complete and st.session_state.structured_data:
    data = st.session_state.structured_data
    original_filename_base = os.path.splitext(st.session_state.original_filename)[0]

    st.markdown("---")
    st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")

    tab1, tab2, tab3 = st.tabs(["ğŸ“„ PDF ì›ë¬¸ ë³´ê¸° (ì´ë¯¸ì§€ ê¸°ë°˜)", "ğŸ’¡ ë¶„ì„ ìš”ì•½ ë° JSON", "ğŸ”¬ í•­ëª©ë³„ ìƒì„¸ ì„¤ëª…"])

    with tab1:
        st.subheader("PDF ì›ë¬¸ ë³´ê¸°")
        if st.session_state.pdf_page_texts:
            total_pages = len(st.session_state.pdf_page_texts)
            # í˜ì´ì§€ ë²ˆí˜¸ ì…ë ¥ê°’ì´ ë³€ê²½ë  ë•Œë§ˆë‹¤ current_page_for_pdf_viewë¥¼ ì—…ë°ì´íŠ¸
            # valueëŠ” 1-basedë¡œ ë³´ì—¬ì£¼ê³ , ë‚´ë¶€ì ìœ¼ë¡œëŠ” 0-based ì‚¬ìš©
            page_selection = st.number_input(
                f"í˜ì´ì§€ ë²ˆí˜¸ (1-{total_pages})",
                min_value=1,
                max_value=total_pages,
                value=st.session_state.current_page_for_pdf_view + 1, # í˜„ì¬ í˜ì´ì§€ + 1ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
                key="pdf_page_selector"
            )
            st.session_state.current_page_for_pdf_view = page_selection - 1


            if 'pdf_bytes_for_viewer' in st.session_state:
                page_image = render_pdf_page_as_image(st.session_state.pdf_bytes_for_viewer, st.session_state.current_page_for_pdf_view, dpi=150)
                if page_image:
                    st.image(page_image, caption=f"í˜ì´ì§€ {st.session_state.current_page_for_pdf_view + 1}/{total_pages}", use_column_width=True)
                else:
                    st.warning(f"í˜ì´ì§€ {st.session_state.current_page_for_pdf_view + 1} ì´ë¯¸ì§€ë¥¼ ë Œë”ë§í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("PDF ë‚´ìš©ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("í‘œì‹œí•  PDF í˜ì´ì§€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab2:
        st.subheader("íŠ¹í—ˆ ê¸°ë³¸ ì •ë³´ (ì¶”ì¶œ ê²°ê³¼ ê¸°ë°˜)")
        if "patent_info" in data and isinstance(data["patent_info"], dict):
            for key, val in data["patent_info"].items():
                display_val = val
                field_title_display = key.replace('_', ' ').title()
                if isinstance(display_val, list):
                    if all(isinstance(item, dict) for item in display_val):
                        st.markdown(f"**{field_title_display}:**")
                        for item_dict in display_val:
                            item_str_list = []
                            for sub_key, sub_val in item_dict.items():
                                item_str_list.append(f"{sub_key.replace('_',' ').title()}: {sub_val}")
                            st.markdown(f"- {', '.join(item_str_list)}")
                    elif display_val: # ë‚´ìš©ì´ ìˆëŠ” ë¦¬ìŠ¤íŠ¸ (ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš°)
                        st.markdown(f"**{field_title_display}:** {', '.join(map(str, display_val))}")
                    else: # ë¹ˆ ë¦¬ìŠ¤íŠ¸
                        st.markdown(f"**{field_title_display}:** ì •ë³´ ì—†ìŒ")

                elif display_val is None:
                    st.markdown(f"**{field_title_display}:** ì •ë³´ ì—†ìŒ")
                else: # ë‹¨ìˆœ ë¬¸ìì—´, ìˆ«ì ë“±
                    st.markdown(f"**{field_title_display}:** {display_val}")

        st.subheader("ë¬¸ì„œ ì „ì²´ ìš”ì•½ (LLM ìƒì„±)")
        summary_val = data.get("document_summary_for_user")
        if summary_val and isinstance(summary_val, str) and summary_val != "ìš”ì•½ ì •ë³´ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.":
            with st.expander("ìš”ì•½ ë³´ê¸°", expanded=True):
                st.info(summary_val)
        else:
            st.warning("ë¬¸ì„œ ìš”ì•½ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        st.subheader("ì¶”ì¶œëœ ì „ì²´ JSON ë°ì´í„°")
        st.json(data, expanded=False)

        try:
            json_string = json.dumps(data, ensure_ascii=False, indent=4)
            st.download_button(
                label="JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=json_string,
                file_name=f"{original_filename_base}_structured_data.json",
                mime="application/json",
                key="json_download_button"
            )
        except Exception as e_json_dl:
            st.error(f"JSON ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e_json_dl}")

    with tab3:
        st.subheader("ì£¼ìš” í•­ëª©ë³„ ìƒì„¸ ì„¤ëª… ë° ì¶”ì¶œ ê°’")
        if "error" in data: # LLM í˜¸ì¶œ ìì²´ì—ì„œ ì˜¤ë¥˜ê°€ ìˆì—ˆë˜ ê²½ìš°
            st.error(f"ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {data.get('error')}")
            if "raw_response" in data: # LLMì˜ ì›ë³¸ ì‘ë‹µì´ ìˆë‹¤ë©´ í‘œì‹œ
                st.text_area("LLM ì›ë³¸ ì‘ë‹µ (ì˜¤ë¥˜ ì‹œ)", data['raw_response'][:2000], height=200)
            if "traceback" in data: # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ íŠ¸ë ˆì´ìŠ¤ë°±ì´ ìˆë‹¤ë©´ í‘œì‹œ
                 st.text_area("ì˜¤ë¥˜ ìƒì„¸ ì •ë³´", data['traceback'], height=200)
        elif not SCHEMA_FIELD_DESCRIPTIONS: # ìŠ¤í‚¤ë§ˆ ì„¤ëª… íŒŒì¼ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°
             st.warning("ìŠ¤í‚¤ë§ˆ ì„¤ëª… ì •ë³´(`schema_descriptions.py`)ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            # SCHEMA_FIELD_DESCRIPTIONS ë”•ì…”ë„ˆë¦¬ì˜ í‚¤(JSON ê²½ë¡œ)ë¥¼ ì •ë ¬í•˜ì—¬ ì„ íƒ ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš©
            # ì‚¬ìš©ìê°€ ë³´ê¸° í¸í•œ ë ˆì´ë¸”ì„ ë§Œë“¤ê±°ë‚˜, ê²½ë¡œ ìì²´ë¥¼ ì˜µì…˜ìœ¼ë¡œ ì œê³µ
            field_options = {
                # ê²½ë¡œì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì„ ë ˆì´ë¸”ë¡œ ì‚¬ìš©í•˜ê³ , ì „ì²´ ê²½ë¡œëŠ” ê°’ìœ¼ë¡œ ì‚¬ìš©. ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì „ì²´ ê²½ë¡œë„ ë ˆì´ë¸”ì— í¬í•¨.
                f"{path.split('.')[-1].replace('_', ' ').title()} (Path: {path})": path
                for path in SCHEMA_FIELD_DESCRIPTIONS.keys()
            }
            # ë ˆì´ë¸” ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            sorted_display_labels = sorted(list(field_options.keys()))

            if not sorted_display_labels:
                st.warning("í‘œì‹œí•  ìŠ¤í‚¤ë§ˆ ì„¤ëª… ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. SCHEMA_FIELD_DESCRIPTIONSë¥¼ ì •ì˜í•´ì£¼ì„¸ìš”.")
            else:
                selected_display_label = st.selectbox(
                    "ìƒì„¸ ì„¤ëª…ì„ ë³´ê³  ì‹¶ì€ í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”:",
                    options=sorted_display_labels,
                    key="field_selector_tab3"
                )

                if selected_display_label and selected_display_label in field_options:
                    selected_path = field_options[selected_display_label] # ì„ íƒëœ ë ˆì´ë¸”ë¡œë¶€í„° ì‹¤ì œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
                    description = SCHEMA_FIELD_DESCRIPTIONS.get(selected_path, "í•´ë‹¹ í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
                    extracted_value = get_value_by_path(data, selected_path)

                    st.markdown(f"#### ğŸ“œ í•­ëª© ê²½ë¡œ: `{selected_path}`")

                    st.markdown("**í•­ëª© ì„¤ëª… (ê³ ì •):**")
                    st.info(description)

                    st.markdown("**ì¶”ì¶œëœ ê°’:**")
                    if extracted_value is None:
                        st.markdown("_ì •ë³´ ì—†ìŒ ë˜ëŠ” í•´ë‹¹ ê²½ë¡œì— ê°’ì´ ì—†ìŠµë‹ˆë‹¤._")
                    elif isinstance(extracted_value, list):
                        if extracted_value:
                            # ë¦¬ìŠ¤íŠ¸ ë‚´ìš©ì´ ë³µì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ st.dataframe ì´ë‚˜ st.jsonìœ¼ë¡œ í‘œì‹œ
                            try:
                                if all(isinstance(i, dict) for i in extracted_value):
                                    st.dataframe(extracted_value)
                                elif all(isinstance(i, (str, int, float, bool)) for i in extracted_value):
                                     st.table(extracted_value) # ê°„ë‹¨í•œ ë¦¬ìŠ¤íŠ¸ëŠ” í…Œì´ë¸”ë¡œ
                                else: # í˜¼í•©ëœ ê²½ìš° ë˜ëŠ” ë³µì¡í•œ ê°ì²´ëŠ” jsonìœ¼ë¡œ
                                    st.json(extracted_value, expanded=True)
                            except Exception: # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ì‹¤íŒ¨ ì‹œ jsonìœ¼ë¡œ ëŒ€ì²´
                                st.json(extracted_value, expanded=True)
                        else:
                            st.markdown("_ë¹ˆ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤._")
                    elif isinstance(extracted_value, dict):
                        st.json(extracted_value, expanded=True)
                    else: # ë¬¸ìì—´, ìˆ«ì, ë¶ˆë¦¬ì–¸ ë“±
                        st.markdown(f"`{extracted_value}`") # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ í‘œì‹œ
                else:
                    st.warning("ì„¤ëª…ì„ í‘œì‹œí•  í•­ëª©ì„ ëª©ë¡ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")

# ì´ˆê¸° í™”ë©´ ì•ˆë‚´
if not uploaded_file:
    st.info("í˜ì´ì§€ ìƒë‹¨ì˜ íŒŒì¼ ì—…ë¡œë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  íŠ¹í—ˆ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")